{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a86c358e-c531-4516-ab3b-c96e00881bfd",
   "metadata": {},
   "source": [
    "# Section 3 - Identifying features that may drive outcomes\n",
    "\n",
    "## Example 3.3\n",
    "\n",
    "**Application 3.3**: Given that a protein has an entanglement, what structural and topological features of that entanglement influence whether or not it is linked with disease?\n",
    "\n",
    "* Not all entanglements are the same - for example, entanglements can differ in the number of contacts that close the loop (**Figure 3.3.1**)\n",
    "![](../images/Nzip-figure.png)\n",
    "\n",
    "**Figure 3.3.1** *Different entanglements have different features. For example, they may differ in the number of native contacts (i.e., non-covalent interactions between amino acids) that close the loop segment. The entanglement shown here has N<sub>zip</sub> = 4.*\n",
    "\n",
    "* In this example we will explore the question of which entanglement features contribute the most to whether or not an entanglement will be linked with disease\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d7dc7c-0843-430e-94df-2f8dff639cd5",
   "metadata": {},
   "source": [
    "### Step 0 - Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ec63ba-a080-4e2d-8cde-a778bf8b8837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_validate\n",
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df401423-986d-488b-8dab-2f97753cf7de",
   "metadata": {},
   "source": [
    "### Step 1 - Load the data & explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66012f99-220f-47bf-b80d-aad8904506fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data8 is a pandas DataFrame object\n",
    "data_path = \"/home/jovyan/data-store/data/iplant/home/shared/NCEMS/BPS-training-2025/\"\n",
    "data8     = pd.read_csv(data_path+\"entanglement-features-disease-assoc.csv\")\n",
    "\n",
    "# drop a few columns that we will not use for this analysis\n",
    "data8     = data8.drop([\"Entanglement\", \"gene\", \"min_N_prot_depth_left\", \"min_C_prot_depth_right\", \"CCBond\"], axis = 1)\n",
    "\n",
    "print (\"The first ten rows of the DataFrame:\\n\")\n",
    "display(data8.head(10))\n",
    "\n",
    "print (\"\\nSome summary information:\\n\")\n",
    "display(data8.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a49b64-3548-4621-b3e0-93b655213be9",
   "metadata": {},
   "source": [
    "* What we are trying to predict is `disease-linked`, which is `Yes` if the protein is linked with disease and `No` if it is not\n",
    "* The features we will use to build the model are all of the columns with the exception of `disease-linked`, which is our outcome\n",
    "* We need to do a few additional processing steps:\n",
    "    * 752 rows do not have a value of `Travatos_G`; we must remove these rows with `NaN` values to avoid errors down the line\n",
    "    * 1 row is also missing `Length`; we will remove this row as well\n",
    "    * We need to check to make sure our features have been scaled correctly and scale them if they have not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a842a8-02fc-4e62-b9c1-072d480e41c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows containing NaN values\n",
    "data8 = data8.dropna(subset = [\"Travatos_G\", \"Length\"])\n",
    "\n",
    "print (\"Some summary information:\\n\")\n",
    "display(data8.info())\n",
    "\n",
    "print (\"\\nHere is additional summary info on the DataFrame:\\n\")\n",
    "data8.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640fda64-8383-4f12-b4e2-61637e3faf05",
   "metadata": {},
   "source": [
    "* We can see from the output of the previous cell that the features have *not* been scaled - we can do this with the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb19132-8345-4d87-8179-5b45d4eef09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform feature scaling\n",
    "features                 = data8.drop(columns = [\"disease-linked\"])\n",
    "outcome                  = data8[\"disease-linked\"]\n",
    "scaler                   = StandardScaler()\n",
    "scaled_features          = scaler.fit_transform(features)\n",
    "scaled                   = pd.DataFrame(scaled_features, columns = features.columns)\n",
    "scaled[\"disease-linked\"] = outcome.reset_index(drop=True)\n",
    "data8                    = scaled\n",
    "\n",
    "# print description of the updated data8 DataFrame\n",
    "data8.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30af3bf7-a797-467f-935b-6c9ab003bdf2",
   "metadata": {},
   "source": [
    "* Now that we have scaled the features, we need to check to see if the outcome classes are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab831a8-2879-4500-b1cb-473fa9fb601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate counts per outcome class\n",
    "class_counts = data8[\"disease-linked\"].value_counts()\n",
    "print (class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d33e45-254a-4b86-b858-a9836c4927bb",
   "metadata": {},
   "source": [
    "* 54% of the proteins have outcome `Yes` and 46% have outcome `No`\n",
    "* The classes are roughly balanced, but it will be important to keep this in mind during training and when assessing our results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfc9a32-0631-4719-b103-23470068f709",
   "metadata": {},
   "source": [
    "### Step 2 - Prepare data for model building\n",
    "\n",
    "* As in **Examples 3.1** & **3.2**, we will use k-fold cross-validation with a grid search over *λ*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f5396e-8ee3-49db-9600-fa5eebe519f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed to achieve reproducible results\n",
    "random_seed = 1\n",
    "\n",
    "# number of folds for cross-validation\n",
    "Nfolds      = 5\n",
    "\n",
    "# we need to recode data in y to be binary integers rather than \"Yes\" and \"No\"\n",
    "recode_map  = {\"Yes\": 1, \"No\": 0}\n",
    "data8['disease-linked'] = data8['disease-linked'].map(recode_map)\n",
    "\n",
    "# define feature and outcome data sets\n",
    "X = data8.drop([\"disease-linked\"], axis = 1)\n",
    "y = data8[\"disease-linked\"]\n",
    "\n",
    "# reserve 20% of data for final testing after hyperparameter tuning\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size = 0.2, random_state = random_seed, stratify=y)\n",
    "\n",
    "# set up k-fold cross-validation with outcome stratification\n",
    "kf          = StratifiedKFold(n_splits = Nfolds, shuffle = True, random_state = 1)\n",
    "\n",
    "# define a range of lambda values to be used in our grid search\n",
    "lambda_vals = np.logspace(-1, 4, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e783d2-8be9-40e2-bd72-b181786edd8b",
   "metadata": {},
   "source": [
    "### Step 3 - Optimize *λ*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ccd419-d04c-4f2e-a9f2-16c7e9c1ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record the start time\n",
    "startTime    = datetime.now()\n",
    "\n",
    "# maximum number of iterations to be run\n",
    "max_iter     = 20000\n",
    "\n",
    "# setup dictionary to store results for each value of lambda\n",
    "results_dict = {}\n",
    "\n",
    "# loop over lambda values\n",
    "for lambda_val in lambda_vals:\n",
    "\n",
    "    # setup logistic regression model\n",
    "    model                    = LogisticRegression(penalty = \"l1\", solver = \"saga\", \n",
    "                                                  max_iter = max_iter, C = 1/lambda_val)\n",
    "\n",
    "    # run cross-validation for current lambda_val\n",
    "    cv_results               = cross_validate(model, X_train, y_train, cv = kf, return_estimator = True, \n",
    "                                              scoring = ['balanced_accuracy', 'roc_auc'], n_jobs = -1)\n",
    "\n",
    "    # store results for later\n",
    "    results_dict[lambda_val] = cv_results\n",
    "\n",
    "    # calculation elapsed time and print it to the screen\n",
    "    elapsed_sec              = (datetime.now() - startTime).total_seconds()\n",
    "    print(f\"{lambda_val:10.4f} {elapsed_sec:10.2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893c54a6-45b0-46a5-8fbe-e3fb2cbc88cc",
   "metadata": {},
   "source": [
    "* As in **3.1** and **3.2**, we will now assess performance and number of features as a function of *λ*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a052076e-9f17-43ad-a833-03f02ae75685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the lambda values\n",
    "lambda_vals = sorted(results_dict.keys())\n",
    "\n",
    "# initialize lists to store the aggregated metric means and standard deviations\n",
    "bal_acc_means, bal_acc_stds = [],[]\n",
    "auroc_means, auroc_stds     = [],[]\n",
    "nonzero_means, nonzero_stds = [],[]\n",
    "\n",
    "# loop over each lambda and compute metrics\n",
    "for lambda_val in lambda_vals:\n",
    "    \n",
    "    cv_results     = results_dict[lambda_val]\n",
    "    \n",
    "    # extract balanced accuracy and AUROC scores\n",
    "    test_bal_acc   = cv_results['test_balanced_accuracy']\n",
    "    test_roc_auc   = cv_results['test_roc_auc']\n",
    "    \n",
    "    # compute mean and standard deviation\n",
    "    mean_bal_acc   = np.mean(test_bal_acc)\n",
    "    std_bal_acc    = np.std(test_bal_acc, ddof=1)\n",
    "    mean_roc_auc   = np.mean(test_roc_auc)\n",
    "    std_roc_auc    = np.std(test_roc_auc, ddof=1)\n",
    "    \n",
    "    # compute number of non-zero coefficients for each fold\n",
    "    nonzero_counts = [np.count_nonzero(estimator.coef_[0]) for estimator in cv_results['estimator']]\n",
    "    mean_nonzero   = np.mean(nonzero_counts)\n",
    "    std_nonzero    = np.std(nonzero_counts, ddof=1)\n",
    "    \n",
    "    # Append the computed metrics to the corresponding lists\n",
    "    bal_acc_means.append(mean_bal_acc)\n",
    "    bal_acc_stds.append(std_bal_acc)\n",
    "    auroc_means.append(mean_roc_auc)\n",
    "    auroc_stds.append(std_roc_auc)\n",
    "    nonzero_means.append(mean_nonzero)\n",
    "    nonzero_stds.append(std_nonzero)\n",
    "\n",
    "# print summary information to screen\n",
    "header = (\"Lambda\".ljust(12) + \"Balanced Acc (mean ± std)\".ljust(27) +\n",
    "          \"AUROC (mean ± std)\".ljust(30) + \"Non-zero Coeffs (mean ± std)\")\n",
    "print(header)\n",
    "\n",
    "for i, lambda_val in enumerate(lambda_vals):\n",
    "    nonzero_str = f\"{nonzero_means[i]:10.1f} ± {nonzero_stds[i]:10.1f}\"\n",
    "    print(f\"{lambda_val:10.4f}\\t\" f\"{bal_acc_means[i]:0.3f} ± {bal_acc_stds[i]:0.3f}\\t\\t\"\n",
    "          f\"{auroc_means[i]:0.3f} ± {auroc_stds[i]:0.3f}\\t\\t\" f\"{nonzero_str}\")\n",
    "\n",
    "# create summary plots\n",
    "plot_color  = \"#004488\"\n",
    "error_color = \"#BB5566\"\n",
    "fig, axes   = plt.subplots(3, 1, figsize=(8, 6), sharex=True)\n",
    "\n",
    "# plot Balanced Accuracy\n",
    "axes[0].errorbar(lambda_vals, bal_acc_means, yerr=bal_acc_stds, fmt='o-', capsize=5, color=plot_color, ecolor=error_color)\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].set_ylabel('Balanced Accuracy')\n",
    "axes[0].set_ylim(0.45, 0.65)\n",
    "axes[0].set_yticks([0.5, 0.55, 0.6])\n",
    "axes[0].set_title('Balanced Accuracy vs Lambda')\n",
    "\n",
    "# plot AUROC\n",
    "axes[1].errorbar(lambda_vals, auroc_means, yerr=auroc_stds, fmt='o-', capsize=5, color=plot_color, ecolor=error_color)\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].set_ylabel('AUROC')\n",
    "axes[1].set_ylim(0.45, 0.75)\n",
    "axes[1].set_yticks([0.5, 0.6, 0.7])\n",
    "axes[1].set_title('AUROC vs Lambda')\n",
    "\n",
    "# plot number of non-zero coefficients\n",
    "axes[2].errorbar(lambda_vals, nonzero_means, yerr=nonzero_stds, fmt='o-', capsize=5,color=plot_color, ecolor=error_color)\n",
    "axes[2].set_xscale('log')\n",
    "axes[2].set_ylabel('# of Non-Zero Coefficients')\n",
    "axes[2].set_title('# of Non-Zero Coefficients vs Lambda')\n",
    "axes[2].set_ylim(-5, 15)\n",
    "axes[2].set_yticks([0, 4, 8, 12])\n",
    "axes[2].set_xlabel('Lambda')\n",
    "\n",
    "# annotate each point with the mean number of non-zero coefficients (to one decimal)\n",
    "for i, lambda_val in enumerate(lambda_vals):\n",
    "    axes[2].annotate(f\"{nonzero_means[i]:.1f}\", (lambda_val, nonzero_means[i]), \n",
    "                     textcoords=\"offset points\", xytext=(5, 5), fontsize=9, color='black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533e24ee-bef2-482c-bd6b-22319b0c0210",
   "metadata": {},
   "source": [
    "### Step 4 - Build & test the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe03fac-d83b-4435-bf16-4c9ea0931fe2",
   "metadata": {},
   "source": [
    "* It appears that we can achieve close to the best results using *λ* = 100 while giving outselves a small number of features to interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60ecbb4-307e-4002-8527-c5cd8521d230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose our preferred value of lambda\n",
    "final_lambda        = 100.\n",
    "\n",
    "# setup the model\n",
    "final_model         = LogisticRegression(penalty=\"l1\", solver=\"saga\", max_iter=max_iter, C=1/final_lambda)\n",
    "\n",
    "# fit the model to the data\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the final model on the holdout dataset\n",
    "y_holdout_pred_prob = final_model.predict_proba(X_holdout)[:, 1]\n",
    "y_holdout_pred      = final_model.predict(X_holdout)\n",
    "holdout_auroc       = roc_auc_score(y_holdout, y_holdout_pred_prob)\n",
    "holdout_bal_acc     = balanced_accuracy_score(y_holdout, y_holdout_pred)\n",
    "\n",
    "print (\"Performance on holdout data\\n\")\n",
    "print(\"Holdout AUROC             :\", '%.3f' %holdout_auroc)\n",
    "print(\"Holdout Balanced Accuracy :\", '%.3f' %holdout_bal_acc, \"\\n\")\n",
    "\n",
    "# extract the nonzero coefficients\n",
    "coef                = final_model.coef_.flatten()\n",
    "nonzero_indices     = coef != 0\n",
    "nonzero_coefs       = coef[nonzero_indices]\n",
    "nonzero_features    = X_train.columns[nonzero_indices]\n",
    "\n",
    "# sort coefficients by absolute magnitude in descending order\n",
    "sorted_indices      = abs(nonzero_coefs).argsort()[::-1]\n",
    "sorted_features     = nonzero_features[sorted_indices]\n",
    "sorted_coefs        = nonzero_coefs[sorted_indices]\n",
    "\n",
    "# print nonzero coefficients\n",
    "print(len(sorted_coefs), \"Nonzero Coefficients (sorted by magnitude)\\n\")\n",
    "for feature, value in zip(sorted_features, sorted_coefs):\n",
    "    print(feature.ljust(26) + \": \" + \"%.5f\" % value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b49e20-023e-48f6-8540-67435fd99e6e",
   "metadata": {},
   "source": [
    "### Step 5 - Assess the results\n",
    "* Take a minute to think about these results:\n",
    "    * How is the model performing?\n",
    "    * How could you begin using this model to generate hypotheses for the importance of certain entanglement features in predicting whether a protein is linked to disease?\n",
    "* When you are done, discuss your answers with at least one person sitting near you.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
