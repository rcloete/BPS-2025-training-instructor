{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28aa56c0-33fe-4128-ba6e-f53ccb37f2ab",
   "metadata": {},
   "source": [
    "# Section 3 - Identifying features that may drive outcomes\n",
    "\n",
    "* Building models that can predict outcomes from a set of features is one of the most common applications of statistics in the sciences\n",
    "* This statistical method is broadly referred to as **regression**\n",
    "* Typically, a scientist selects a set of features that they think influence their outcome and builds a (linear, logistic, *etc.*) model based on these features\n",
    "* Least Absolute Shrinkage and Selection Operator (**LASSO**, also termed **L1 regularization**) is one regression method that helps identify features that drive outcomes\n",
    "    * In simple terms, LASSO builds a model using all features as independent variables\n",
    "    * Some coefficients for features are allowed to pass to zero if they do not strongly influence the results\n",
    "    * LASSO thus provides **feature selection** by determining which features are most important to predicting the outcome\n",
    "* As we will see, the features that do not drop out of the analysis may be helpful in generating hypotheses "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e008785b-4232-4eaa-b808-7eb7ea27618b",
   "metadata": {},
   "source": [
    "## Example 3.1\n",
    "**Application 3.1**: Determining which features predict whether or not a segment of amino acids will be involved in an entanglement\n",
    "\n",
    "* For this application we will use a dataset of 810 features computed for proteins in yeast\n",
    "* Each protein was broken up into 9 amino acid segments using a sliding window (*e.g.*, residues [1-9] form segment 1, residues [2-10] form segment 2, *etc.*)\n",
    "* This is a binary classification problem - we want to predict which segments will be entangled (outcome = 1) and which will not be entangled (outcome = 0)\n",
    "* As we are trying to predict a binary outcome, we will apply LASSO to **logistic regression**\n",
    "* Let's get started on our analysis in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99829c05-e19d-4b13-8809-30c4946d5221",
   "metadata": {},
   "source": [
    "### Step 0 - Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ebc7b7-be7d-43f0-a6fb-57e27ab24646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_validate\n",
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67163f7b-10f6-46dd-bc8d-5114e0c375b0",
   "metadata": {},
   "source": [
    "### Step 1 - Load the data & explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f397c5-fb86-49bd-96a5-722ee576b982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data set as a pandas DataFrame object\n",
    "data_path = \"/home/jovyan/data-store/data/iplant/home/shared/NCEMS/BPS-training-2025/\"\n",
    "data6     = pd.read_csv(data_path+\"yeast-processed_v2.csv\")\n",
    "\n",
    "print (\"Create a quick summary of the DataFrame:\\n\")\n",
    "data6.info()\n",
    "\n",
    "print (\"\\nVisualize the first ten rows of the DataFrame:\\n\")\n",
    "display(data6.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ac1a78-2720-4a96-bc6b-402f1dd62a2a",
   "metadata": {},
   "source": [
    "* We have 811 columns corresponding to the 810 feature columns and the single outcome column\n",
    "* In this instance, the outcome we are trying to predict is named `target_value`\n",
    "* We will now check to see if the feature space has been scaled correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9c51a4-f0de-46da-a7b1-be52e68ef792",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"\\nInformation about mean and standard deviation of parameters:\")\n",
    "data6.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8abb59-995f-4d17-b25d-b747573e91a2",
   "metadata": {},
   "source": [
    "* Critically, we can see that the feature space has already been scaled such that each feature has a **mean of zero** and a **standard deviation of one**\n",
    "* We need to check one final thing about our data set - whether or not the outcome classes are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1262de1-d340-4ec1-ba34-447cabc2d805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate counts per outcome class\n",
    "class_counts = data6[\"target_value\"].value_counts()\n",
    "print (class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06124dcd-edf7-4ac9-a071-50e3ac41b199",
   "metadata": {},
   "source": [
    "* The outcome classes are perfectly balanced with 7,500 occurrances of both `0` and `1` - we are ready to proceed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167e58e9-ad45-4812-b5c4-d3f3f405db4f",
   "metadata": {},
   "source": [
    "### Step 2 - Prepare data for model building\n",
    "\n",
    "* We need to split our complete dataset of 15,000 entries into three portions:\n",
    "    * 1 - a dataset used to **train** the model *during* parameter tuning\n",
    "    * 2 - a dataset used to **test** the model *during* parameter tuning\n",
    "    * 3 - a **holdout** dataset used to **test** performance *after* parameter tuning\n",
    "* We will first reserve a holdout dataset for final testing and use the rest for model training and parameter tuning\n",
    "* In this example, we will use **k-fold cross validation** paired with a grid search to select the value of *λ*, the **hyperparameter** that determines the strength of regularization (how aggressively coefficients are collapsed to zero) in LASSO, while training and testing the model simultaneously\n",
    "* In `sklearn`, regularization strength is controlled by the hyperparameter C = 1/*λ*\n",
    "\n",
    "### K-Fold Cross Validation\n",
    "\n",
    "* In **k-fold cross validation**, the set of non-holdout data is split into various different train-test subsets (**Figure 3.1.1**)\n",
    "\n",
    "![](../images/K-fold_cross_validation_EN.png)\n",
    "\n",
    "**Figure 3.1.1**. *In k-fold cross validation, every data point will be used to both train & test the model. Modified from https://en.wikipedia.org/wiki/Cross-validation_(statistics)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cd8817-146a-42fa-9a1c-0038df8163d9",
   "metadata": {},
   "source": [
    "* The cell below sets up the data splitting - we will reserve 20% of the data for final testing and use the other 80% for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acfd940-798b-4d87-bc5a-79e0d3cae461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a random seed to get deterministic behavior\n",
    "random_seed = 1\n",
    "\n",
    "# number of folds for cross-validation\n",
    "Nfolds      = 5\n",
    "\n",
    "# define feature and outcome datasets\n",
    "X           = data6.drop(columns=[\"target_value\"])\n",
    "y           = data6[\"target_value\"]\n",
    "\n",
    "# reserve 20% of data for final testing after hyperparameter tuning\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size=0.2, random_state=random_seed, stratify=y)\n",
    "\n",
    "# set up k-fold cross-validation with outcome stratification\n",
    "kf = StratifiedKFold(n_splits=Nfolds, shuffle=True, random_state=random_seed)\n",
    "\n",
    "# set up set of lambda values for hyperparameter tuning\n",
    "lambda_vals = np.logspace(-1, 4, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1cd0d0-ea12-424a-9153-a8aab0e28e79",
   "metadata": {},
   "source": [
    "### Step 3 - Optimize *λ*\n",
    "* We are ready to run cross-validation and select the value of *λ*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99459505-79b2-4dca-ac98-705a68d110d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the start time of the cell\n",
    "startTime    = datetime.now()\n",
    "\n",
    "# maximum number of iterations to be run\n",
    "max_iter     = 10000\n",
    "\n",
    "# setup dictionary to store results for each value of lambda\n",
    "results_dict = {}\n",
    "\n",
    "# loop over lambda values\n",
    "for lambda_val in lambda_vals:\n",
    "\n",
    "    # setup logistic regression model\n",
    "    model                    = LogisticRegression(penalty=\"l1\", solver=\"saga\", \n",
    "                                                  max_iter=max_iter, C=1/lambda_val)\n",
    "\n",
    "    # run cross-validation for current lambda_val\n",
    "    cv_results               = cross_validate(model, X_train, y_train, cv=kf, return_estimator=True, \n",
    "                                              scoring=['balanced_accuracy', 'roc_auc'], n_jobs=-1)\n",
    "\n",
    "    # store results for later\n",
    "    results_dict[lambda_val] = cv_results\n",
    "\n",
    "    # calculation elapsed time and print it to the screen\n",
    "    elapsed_sec              = (datetime.now() - startTime).total_seconds()\n",
    "    print(f\"{lambda_val:10.4f} {elapsed_sec:10.2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c5abc5-cd44-42b4-b2b1-d9154414385a",
   "metadata": {},
   "source": [
    "* Now that we have run cross-validation for each value of *λ*, let's assess the results\n",
    "* We will use two performance metrics:\n",
    "    * **Balanced accuracy**\n",
    "        * Balanced accuracy = 1 indicates perfect predictions\n",
    "        * Balanced accuracy = 0.5 indicates random classification\n",
    "        * Balanced accuracy < 0.5 indicates *worse* than random classification \n",
    "    * Area Under the Receiver Operating Characteristic Curve (**AUROC**)\n",
    "        * AUROC = 1 indicates perfect classification\n",
    "        * AUROC = 0.5 indicates random classification\n",
    "        * AUROC < 0.5 indicates worse than random classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83327f07-1a07-4928-af91-333a45d9ddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the lambda values\n",
    "lambda_vals                 = sorted(results_dict.keys())\n",
    "\n",
    "# initialize lists to store the aggregated metric means and standard deviations\n",
    "bal_acc_means, bal_acc_stds = [],[]\n",
    "auroc_means, auroc_stds     = [],[]\n",
    "nonzero_means, nonzero_stds = [],[]\n",
    "\n",
    "# loop over each lambda and compute metrics\n",
    "for lambda_val in lambda_vals:\n",
    "    \n",
    "    cv_results     = results_dict[lambda_val]\n",
    "    \n",
    "    # extract balanced accuracy and AUROC scores\n",
    "    test_bal_acc   = cv_results['test_balanced_accuracy']\n",
    "    test_roc_auc   = cv_results['test_roc_auc']\n",
    "    \n",
    "    # compute mean and standard deviation\n",
    "    mean_bal_acc   = np.mean(test_bal_acc)\n",
    "    std_bal_acc    = np.std(test_bal_acc, ddof=1)\n",
    "    mean_roc_auc   = np.mean(test_roc_auc)\n",
    "    std_roc_auc    = np.std(test_roc_auc, ddof=1)\n",
    "    \n",
    "    # compute number of non-zero coefficients for each fold\n",
    "    nonzero_counts = [np.count_nonzero(estimator.coef_[0]) for estimator in cv_results['estimator']]\n",
    "    mean_nonzero   = np.mean(nonzero_counts)\n",
    "    std_nonzero    = np.std(nonzero_counts, ddof=1)\n",
    "    \n",
    "    # Append the computed metrics to the corresponding lists\n",
    "    bal_acc_means.append(mean_bal_acc)\n",
    "    bal_acc_stds.append(std_bal_acc)\n",
    "    auroc_means.append(mean_roc_auc)\n",
    "    auroc_stds.append(std_roc_auc)\n",
    "    nonzero_means.append(mean_nonzero)\n",
    "    nonzero_stds.append(std_nonzero)\n",
    "\n",
    "# print summary information to screen\n",
    "header = (\"Lambda\".ljust(12) + \"Balanced Acc (mean ± std)\".ljust(27) +\n",
    "          \"AUROC (mean ± std)\".ljust(30) + \"Non-zero Coeffs (mean ± std)\")\n",
    "print(header)\n",
    "\n",
    "for i, lambda_val in enumerate(lambda_vals):\n",
    "    nonzero_str = f\"{nonzero_means[i]:10.1f} ± {nonzero_stds[i]:10.1f}\"\n",
    "    print(f\"{lambda_val:10.4f}\\t\" f\"{bal_acc_means[i]:0.3f} ± {bal_acc_stds[i]:0.3f}\\t\\t\"\n",
    "          f\"{auroc_means[i]:0.3f} ± {auroc_stds[i]:0.3f}\\t\\t\" f\"{nonzero_str}\")\n",
    "\n",
    "# create summary plots\n",
    "plot_color  = \"#004488\"\n",
    "error_color = \"#BB5566\"\n",
    "fig, axes   = plt.subplots(3, 1, figsize=(8, 6), sharex=True)\n",
    "\n",
    "# plot Balanced Accuracy\n",
    "axes[0].errorbar(lambda_vals, bal_acc_means, yerr=bal_acc_stds, fmt='o-', capsize=5, color=plot_color, ecolor=error_color)\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].set_ylabel('Balanced Accuracy')\n",
    "axes[0].set_title('Balanced Accuracy vs Lambda')\n",
    "axes[0].set_ylim(0.45, 0.85)\n",
    "axes[0].set_yticks([0.5, 0.6, 0.7, 0.8])\n",
    "\n",
    "# plot AUROC\n",
    "axes[1].errorbar(lambda_vals, auroc_means, yerr=auroc_stds, fmt='o-', capsize=5, color=plot_color, ecolor=error_color)\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].set_ylabel('AUROC')\n",
    "axes[1].set_title('AUROC vs Lambda')\n",
    "axes[1].set_ylim(0.45, 0.95)\n",
    "axes[1].set_yticks([0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "\n",
    "# plot number of non-zero coefficients\n",
    "axes[2].errorbar(lambda_vals, nonzero_means, yerr=nonzero_stds, fmt='o-', capsize=5,color=plot_color, ecolor=error_color)\n",
    "axes[2].set_xscale('log')\n",
    "axes[2].set_ylabel('# of Non-Zero Coefficients')\n",
    "axes[2].set_title('# of Non-Zero Coefficients vs Lambda')\n",
    "axes[2].set_ylim(-25, 600)\n",
    "axes[2].set_yticks([0, 100, 200, 300, 400, 500, 600])\n",
    "axes[2].set_xlabel('Lambda')\n",
    "\n",
    "# annotate each point with the mean number of non-zero coefficients (to one decimal)\n",
    "for i, lambda_val in enumerate(lambda_vals):\n",
    "    axes[2].annotate(f\"{nonzero_means[i]:.1f}\", (lambda_val, nonzero_means[i]), \n",
    "                     textcoords=\"offset points\", xytext=(5, 5), fontsize=9, color='black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeed6787-68cf-4072-ab0b-929a0ab6d707",
   "metadata": {},
   "source": [
    "* With LASSO, we get to choose our preferred trade off between number of non-zero features and performance.\n",
    "* In this case, we can achieve strong performance with *λ* = 1,000 and have only 4 features to consider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a60603-5230-4c7f-97b2-30694ffccc9e",
   "metadata": {},
   "source": [
    "### Step 4 - Build & test the final model\n",
    "* We can now construct the final model by training on all data except the holdout dataset with *λ* = 1000.\n",
    "* After training the final model, we will test its performance on the unseen holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f012c4-b960-4e05-9803-8c5469463a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose our preferred value of lambda\n",
    "final_lambda        = 1000.\n",
    "\n",
    "# setup the model\n",
    "final_model         = LogisticRegression(penalty=\"l1\", solver=\"saga\", max_iter=max_iter, C=1/final_lambda)\n",
    "\n",
    "# fit the model to the data\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the final model on the holdout dataset\n",
    "y_holdout_pred_prob = final_model.predict_proba(X_holdout)[:, 1]\n",
    "y_holdout_pred      = final_model.predict(X_holdout)\n",
    "holdout_auroc       = roc_auc_score(y_holdout, y_holdout_pred_prob)\n",
    "holdout_bal_acc     = balanced_accuracy_score(y_holdout, y_holdout_pred)\n",
    "\n",
    "print (\"Performance on holdout data\\n\")\n",
    "print(\"Holdout AUROC             :\", '%.3f' %holdout_auroc)\n",
    "print(\"Holdout Balanced Accuracy :\", '%.3f' %holdout_bal_acc)\n",
    "\n",
    "# extract the nonzero coefficients\n",
    "coef                = final_model.coef_.flatten()\n",
    "nonzero_indices     = coef != 0\n",
    "nonzero_coefs       = coef[nonzero_indices]\n",
    "nonzero_features    = X_train.columns[nonzero_indices]\n",
    "\n",
    "# sort coefficients by magnitude in descending order\n",
    "sorted_indices      = abs(nonzero_coefs).argsort()[::-1]\n",
    "sorted_features     = nonzero_features[sorted_indices]\n",
    "sorted_coefs        = nonzero_coefs[sorted_indices]\n",
    "\n",
    "# print nonzero coefficients\n",
    "print(\"\\nNonzero Coefficients (sorted by magnitude)\\n\")\n",
    "for feature, value in zip(sorted_features, sorted_coefs):\n",
    "    print(feature.ljust(26) + \": \" + \"%.5f\" % value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ce5701-b0a5-4262-8db9-302b31f6d8fe",
   "metadata": {},
   "source": [
    "### Step 5 - Assess the results\n",
    "* We observe that there are five rather than four non-zero features - we expect some differences between this final model, parameterized based on the entire training set, and those trained during cross-validation\n",
    "* These non-zero features can serve as the basis for hypothesis generation; for example:\n",
    "    *  Why is `CN_exp`, which represents the local packing density of a set of residues, important to our ability to predict the outcome?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
